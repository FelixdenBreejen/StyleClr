{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "import adain.net as net\n",
    "\n",
    "from styleclr.test import test_transform, style_transfer\n",
    "from styleclr.utils import move_to_top_directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/felix/styleclr'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "move_to_top_directory()\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = Path('output')\n",
    "decoder_path = Path('adain/models/decoder.pth')\n",
    "vgg_path = Path('adain/models/vgg_normalised.pth')\n",
    "content_size = 512\n",
    "style_size = 512\n",
    "crop = False\n",
    "alpha = 1\n",
    "save_ext = '.jpg'\n",
    "\n",
    "content_path = Path('adain/input/content/avril.jpg')\n",
    "style_path = Path('adain/input/style/asheville.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "decoder = net.decoder\n",
    "vgg = net.vgg\n",
    "\n",
    "decoder.eval()\n",
    "vgg.eval()\n",
    "\n",
    "decoder.load_state_dict(torch.load(decoder_path))\n",
    "vgg.load_state_dict(torch.load(vgg_path))\n",
    "vgg = nn.Sequential(*list(vgg.children())[:31])\n",
    "\n",
    "vgg.to(device)\n",
    "decoder.to(device)\n",
    "\n",
    "content_tf = test_transform(content_size, crop)\n",
    "style_tf = test_transform(style_size, crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = content_tf(Image.open(str(content_path)))\n",
    "style = style_tf(Image.open(str(style_path)))\n",
    "\n",
    "style = style.to(device).unsqueeze(0)\n",
    "content = content.to(device).unsqueeze(0)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = style_transfer(vgg, decoder, content, style, alpha)\n",
    "output = output.cpu()\n",
    "\n",
    "output_name = output_dir / '{:s}_stylized_{:s}{:s}'.format(\n",
    "    content_path.stem, style_path.stem, save_ext)\n",
    "save_image(output, str(output_name))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6885236db0707012bea2e5454d574dd637058409a2f50ac4f974dcbbde53bfd4"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('styleclr')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
